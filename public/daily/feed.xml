<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">

<channel>
   <title>ephjos daily</title>
   <description>daily thoughts</description>
   <language>en-us</language>
   <link>http://ephjos.io/daily/feed.xml</link>
   <atom:link href="http://ephjos.io/daily/feed.xml" rel="self" type="application/rss+xml" />


      <item>
        <title>15</title>
        <link>http://ephjos.io/daily/2021/10/21</link>
        <guid>http://ephjos.io/daily/2021/10/21</guid>
        <pubDate>Thu, 21 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <p>         From my limited experience, over-communicating seems like the best         approach to default to. I find myself hesitating when feeling like I         need to ask a question. In order to ask the question comfortably, I         have to feel like I've done my work first. I hate the feeling of asking         first, only to be told the answer is trivial. However, I've also found         myself deep in a rabbit hole that I did not have to go down many times         before as well. If I were to instead err on the side of         over-communicating, I can quite easily correct back. Often, especially         in high-paced work environments, people can be missing the full picture.         By over sharing you can help prevent team members from being lost and         aid them in accomplishing their goals. Under sharing leads to         miscommunication which can have drastic consequences. Over sharing         can be a temporary inconvenience.          <p>         I was given some advice the other day:          <blockquote>           If you do not feel like you are over-communicating, then you are           not communicating enough.         </blockquote>          <p>         Over-communicate.  
        ]]></description>
      </item>
    

      <item>
        <title>14</title>
        <link>http://ephjos.io/daily/2021/10/20</link>
        <guid>http://ephjos.io/daily/2021/10/20</guid>
        <pubDate>Wed, 20 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <p>         When working on a piece of code, I am trying to be more mindful of         assumptions. It is easy enough to write down my assumptions while         reading code. This helps me check myself, and makes it easy to ask a         teammate targeted questions that can be answered with relative ease.         What's more difficult is checking external assumptions. In conversation,         it can be tricky to navigate but useful to ask someone "Are you assuming         X?". When done correctly, this can help everybody involved get on the         same page and focus on the task at hand. We also have to watch out for         assumptions in code we are monitoring. Some of these can be obvious,         laid out in a comment. Much like listing your own assumptions, these         are easy enough to verify. The danger comes from implicit assumptions.          <p>         We've all read and written functions that make assumptions about the         parameters that they are passed. This is especially dangerous in a         dynamically typed language, where any parameter can be any value.         Static typing does not wholly prevent this problem as there may be         edge cases within a type that must be accounted for. A function can         verify that its parameter is a number, but if it divides by that number         without checking it to be non-zero, then there are still dangerous         assumptions in the code.          <p>         These dangers extend past parameters and into all logic within a         program. We make assumptions about data flow, execution order, data         models, etc. that are all core to what the code does. While some of         these are unavoidable (i.e. synchronous code executes in order) we must         be mindful of all internal and external assumptions. Err on the side         of over communicating about these assumptions to better help your         team understand the piece of code being discussed. Pay close attention         to the code you read and write and be aware of any assumptions made         within.          <p>         Always check assumptions.  
        ]]></description>
      </item>
    

      <item>
        <title>13</title>
        <link>http://ephjos.io/daily/2021/10/19</link>
        <guid>http://ephjos.io/daily/2021/10/19</guid>
        <pubDate>Tue, 19 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <img           alt="Compounding growth chart"           src="/img/compounding.png">         <blockquote>           Compounding growth chart showing $100 monthly contribution           with 5% annual interest over 40 years, starting with 0 initial           investment.         </blockquote>          <p>         One of the first lessons you should learn once you become interested in         personal finance is that compounding interest is one of the most         powerful tools for building wealth. Over large time scales, small         compounding interest can have incredible effects. Getting 5% interest         on repeated savings can lead to doubling your money in about 30 years;         and lead to tripling it in 40. The gradual nature of this growth         means that gains are not apparent for the majority of the time. After         investing a significant amount of time and resources, compounding         interest starts to take over. In the above example, the 40th year of         interest provides the same gain as the first ~18 combined. Exponential         growth seems to be unintuitive and can seem insignificant, barely         greater than linear for most of the time.          <p>         I once heard the following puzzle that someone was using to help educate         people about compounding and exponential growth.          <blockquote>           There is a lake with nothing else but a single lily pad. Every day,           the amount of lily pads doubles. If it takes the lily pads 50           days to cover the entire lake, how long does it take them to cover           half of it?         </blockquote>          <p>         49 days, doubling on the last day to cover the whole lake. The         fascinating thing to me was how sudden this burst at the end is. At day         45, the lily pads only take up 3% of the lake's surface area. The growth         for these first 45 was slow and largely undetectable day-to-day. The         last 5 days see a jump from 3% to 100% coverage. After a quick search,         here is a resource with this same scenario from a University of Washington professor:         <a href="https://atmos.uw.edu/~dennis/211_Exponential_Growth.pdf">Information sheet on exponential growth</a>.          <p>         I believe that this pattern can be seen everywhere, especially in         software projects.         Small investments that can be made on a regular basis provide a         seemingly disproportionate return over time. I think most developers         have seen this on a shorter time scale, say a couple of months. First,         there are a couple months of PRs that fix bugs and refactor code         without providing much value to the end user. Then, seemingly out of         nowhere, there are a handful of PRs that have a cascading effect leading         to dozens of issues being closed. The reality is that <i>all</i> of the         work done in those few months is responsible for the fixes at the end,         just that there needed to be a significant investment before         the true return could be realized.          <p>         This is the core idea behind James Clear's         <a href="https://jamesclear.com/continuous-improvement">1% better every day</a>         idea, which was deeply profound to me the first time I came across it.          <p>         Small continuous improvements lead to compounding growth.  
        ]]></description>
      </item>
    

      <item>
        <title>12</title>
        <link>http://ephjos.io/daily/2021/10/18</link>
        <guid>http://ephjos.io/daily/2021/10/18</guid>
        <pubDate>Mon, 18 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <p>         Today I was able to finish the canvas chapter of the Ray Tracer Challenge         in racket. I spend a good bit of time digging through the racket docs         on basic string building and was able to get everything working.         The usage of vectors for storing the pixel data feels fast, but         converting the         pixel data to the output (PPM) string is slow.         This is somewhat expected, but is still a point of concern.         There are two aspects of this process that slow it down: converting         the vector to a list and string concatenation. Ideally, I would         directly pull the data out of the vector and add it to buffer, which         could then be written to the output file. The current implementation         uses higher-level string functions that will likely crush performance         going forward. This should not bring things to a halt, and the output         should still always be generated. Regardless, I expect to be back in         this code in the near future.          <p>         If I was to do this in Java, I would pull the information directly out         of an <code>Array</code> and append it to a <code>StringBuilder</code>.         Then, the <code>StringBuilder</code> could write its contents to the         output file. This solution would be quick and easy to read. I should         be able to get similar performance out of racket, once I learn more.  
        ]]></description>
      </item>
    

      <item>
        <title>11</title>
        <link>http://ephjos.io/daily/2021/10/17</link>
        <guid>http://ephjos.io/daily/2021/10/17</guid>
        <pubDate>Sun, 17 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <p>         Another slight mindset shift I am trying to make is to focus on         problems, not solutions. This idea is parroted around a lot especially         in online-entrepreneur-influencer circles, but I think it does have         some value. As someone who can obsess over what the "best"         solution to a problem is and make the entire process much more difficult         for         himself, this tweak may prove helpful. Instead of being occupied         purely with the solution, pour more time and effort into learning about         the problem. The classic questions of who, what, where, when, why, and         how are all of the tools needed here.          <p>         The core hypothesis behind this idea is that a good solution should be         evident from the problem, once you have enough data about the problem.         Instead of languishing about large-scale architecture mistakes and         refactors, focus on the specific issue at hand. If the original author         is still on the team, reach out to them for some information. A quick         slack message may illuminate something before unseen to you. Identify         exactly what the issue is, and try to keep this definition targeted.         Pinpoint exactly where in both the code and the product this issue         occurs. Enumerate every place where this is the case, which may be         helpful for testing at the end. Understand what decisions/mistakes led         to this issue being checked-in to the code base. List out all of the         different manners in which the issue can be caused. Is it reproducible?         Is it deterministic? Given all of this information on top of the code         itself, clearly explain how the issue occurs. From code decisions to         what manifests to the end user, you should be able to explain each step         along the way and what key pieces lead to the final result.          <p>         With this detailed of a view on the problem, a list of potential         solutions should become immediately clear. Rank these solutions and         get feedback from team members (if necessary) before moving forward with         the best choice. Don't treat this is as a binding agreement: more         information may become available while working on this fix that reveals         another solution as a better choice. If unconstrained by time, feel free         to switch to the new approach.          <p>         Instead of focusing on the solution, obsess over the problem. Gather         info and make an educated decision on how to best tackle the problem.         The end goal is to fix the issue, not to create an elegant solution.         If the investigation into the problem is done right, this should         happen largely on its own.          <p>         Well defined problems reveal elegant solutions.  
        ]]></description>
      </item>
    

      <item>
        <title>10</title>
        <link>http://ephjos.io/daily/2021/10/16</link>
        <guid>http://ephjos.io/daily/2021/10/16</guid>
        <pubDate>Sat, 16 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <p>         When working on a large project, knowing whether or not a pull request         is "good" can be difficult. We can find ourselves in abstract         discussions of what the best approach should be or leaving review         that "maybe you could fix X too". While these conversations have value,         they are not pragmatic and don't directly lead to code changes and PRs         being merged.          <p>         I am working on having a mindset focused on incremental improvement.         If a PR makes an undeniable improvement to the code base and does not         introduce any bugs or debt, then it should         be merged. If every PR can provide some improvement and be turned around         quickly, a team can rapidly rid themselves of the problems they spend         so much time discussing.          <p>         It is hard to walk the line between "fix everything" and "make         the project better", but I think it can (and should) be done. Identify         the core issues, create PRs to fix them, and merge the PRs. The ideal         PR is likely         <i>small and targeted</i> instead of         <i>large and perfect</i>. Over time, the smaller PRs can be merged faster,         provide a smaller surface area for bugs, and approach the perfect solution.  
        ]]></description>
      </item>
    

      <item>
        <title>9</title>
        <link>http://ephjos.io/daily/2021/10/15</link>
        <guid>http://ephjos.io/daily/2021/10/15</guid>
        <pubDate>Fri, 15 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <p>         After briefly getting into racket's vectors, I am becoming a bit         more hopeful of finishing the Ray Tracer Challenge in racket. They         are default mutable         and come with analogs for most of the standard list functions (map,         filter, etc.). While I like pure functional programming and understand         the value, mutability can provide great performance improvements         in some cases (like         ray tracing). I'll be using vectors in the canvas struct, which contains         an RGB tuple for each pixel in the image we are trying to generate.         I believe that the source of the issues I ran into in Haskell was precisely         writing pixels to the canvas. Instead of having to copy the canvas to         do writes, simply get a reference to the pixel data and update a color         at a specific location. No need to worry about passing around and using         as State monad (which I still have not figured out how to do), just update         the value in place. This is exciting!          <p>         On a related note, I can never figure out a naming for "mathematical         vectors" when using them alongside vector containers. I need to use         the standard         library's <code>make-vector</code> to create the pixel data container.         This meant that I needed to rename my 3D vector (and point since they         are both "tuples"). I've gone with <code>make-vector-3d</code> in         this case, but I'd rather call the container an <i>ArrayList</i>         instead.         Or, since "list" is the default container type         in racket, <i>Array</i> would work just fine and make sense. 
        ]]></description>
      </item>
    

      <item>
        <title>8</title>
        <link>http://ephjos.io/daily/2021/10/14</link>
        <guid>http://ephjos.io/daily/2021/10/14</guid>
        <pubDate>Thu, 14 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <p>         I love simple tools.          <p>         Reflecting on some of what I talked about         <a href="/daily/2021/10/13">yesterday</a>,         I realized something else about myself. While friction and         resistance can be crippling, having too much freedom can be just as         bad. I notice this particularly with tooling I use often. Bells and         whistles do a great job of distracting me, and I will sink a         disproportionate amount of time into something that is practically         insignificant.          <p>         I think this part of my personality is what drew me to Linux.         The opportunity for endless customization and control was exciting         and pulled me in. I have spent countless hours customizing different         dotfiles and settings, a lot of which I use less than once a month.         While this is great educational value in this level of curiosity,         it does sometimes get in the way.          <p>         I've found that by focusing on a small set of simple and extendable         tools, I can get myself to focus on the problems I am trying to solve         much easier. Now that I am familiar with these tools, I can use, tweak,         update, and fix them without worry and (largely) without distraction.         There are fewer moving parts, no batteries to charge, no oil to change:         just a hammer to swing at a problem. While I understand and still         feel the allure of cool screenshots and retro programs, I find I enjoy         using a computer more by keeping it simple.  
        ]]></description>
      </item>
    

      <item>
        <title>7</title>
        <link>http://ephjos.io/daily/2021/10/13</link>
        <guid>http://ephjos.io/daily/2021/10/13</guid>
        <pubDate>Wed, 13 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <p>         Last year, in the first summer of the pandemic, I listened to James         Clear's         <a href="https://jamesclear.com/atomic-habits">Atomic Habits</a> on         audiobook during my workouts. I found the ideas discussed within         to be fascinating and their application to be more intriguing. Of all         of the ideas discussed in the book, the most well known is probably the         idea of habit chaining. The idea here is that it is near impossible to         take on a bunch of new habits simultaneously, especially when they are         all disconnected. Instead, it is easier to "attach" a habit to an         existing one. If you want to write every morning, and you already have         the habit of waking up and making a cup of coffee, you can try chaining         writing onto the existing habit. Instead of trying to "write a blog post         everyday", aim to "write for 10 minutes <i>after</i> making coffee". This is         a smaller habit that builds up your existing system. There is lower         friction when trying to start the new task, since you are riding on         the momentum of your existing habit. With coffee in hand, you are         already prepped for and 10 minutes of writing away from completing         the task. Once you are writing everyday, it is easy to increase the         amount of time spent writing since you already have the habit of starting.          <p>         Remove the need         for motivation and instead make what you want to do easy, and what         you don't want to do hard. Its easier to eat healthy if you only have         healthy foods in the house; it is hard to east unhealthy if you only         have healthy foods in the house. This resonates with me the most         since I tend to <i>over-perceive</i> the amount of friction involved         in tasks.          <p>         When not part of a habit, simple tasks can become daunting and take         me a while to decide to do. I find that by trying to see the         true level of friction, I can "motivate" myself to do these tasks much         easier. Instead of being worried about how complicated a new feature         may be and how long it will take to implement and all of the potential         bugs that may be introduced: just start. Version control is a great         tool which allows us to undo or fix changes with ease.          <p>         For me, habits are best built by lowering the cognitive effort necessary         to start them, increasing the friction of the opposite task, and spending         what cognitive effort is necessary to analyze the true friction of the         task. It is less about finding the motivation than it is about         overcoming this "resistance" towards all tasks. Given these traits,         I seem to function best by simplifying the tools and systems around         me. I've found that         <a href="https://en.wikipedia.org/wiki/KISS_principle">"Keep It Simple, Stupid"</a>         tends to work for me. 
        ]]></description>
      </item>
    

      <item>
        <title>6</title>
        <link>http://ephjos.io/daily/2021/10/12</link>
        <guid>http://ephjos.io/daily/2021/10/12</guid>
        <pubDate>Tue, 12 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <p>         After some discussions about unit tests at work yesterday, I came across         this solid <a href="https://softwareengineering.stackexchange.com/a/356238">StackExchange</a>         post. It turns out my understanding of the ways that a unit test can be         brittle were fairly limited, meaning I missed a few of the bad ways to         write unit tests. In particular, I previously would add in additional         checks that "just made sure" for different values/functionality along         the way. Often, these checks were almost completely orthogonal to the target         of the unit test. I saw this as more stable (more tests = better)         not as more brittle. But, now I understand the perspective that         extraneous assertions can lead to tests failing even when their "core"         tests pass. A rule of thumb to try going forward: strive to have         only 1 assert per unit test. While this is admittedly impractical and         not always the best approach, I think it is the kind of correction         I need to make in my approach.          <p>         On a different note, Ethan Chlebowski's recipe for         <a href="https://www.ethanchlebowski.com/cooking-techniques-recipes/street-cart-chicken-amp-yellow-rice">halal cart style chicken and rice</a>         is fantastic. I didn't think it would be so easy to recreate a         freshman year favorite of mine at home. If I exercise control         by making the salad portion bigger, rice portion smaller, and using a touch less         sauce, this is actually a solid healthy meal.          <p>         The most important         contribution Ethan has made to my cooking is his mayo marinade technique         which is applied in the above recipe. Instead of oil, marinate your         meat in a seasoned mayo which is oil+egg+vinegar. This results in         more tender, juicer meat with the bonus of not having to worry about         putting fat in the pan: the meat brings enough fat to cook it from         the marinade. The usage of mayo here also provides incredible color         to the finished product, which is always great to have. 
        ]]></description>
      </item>
    

      <item>
        <title>5</title>
        <link>http://ephjos.io/daily/2021/10/11</link>
        <guid>http://ephjos.io/daily/2021/10/11</guid>
        <pubDate>Mon, 11 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <p>         Thanks to Tyson Fury vs. Deontay Wilder 3 causing me to stay up until         1:30am Saturday night, I am beat this morning. It was well worth it.         I am hoping a good workout         and some caffeine will help before the real work of the day begins.          <p>         I have found myself spending more and more time reviewing PRs, which         has been a great experience. This doesn't feel like it is cutting into         my other work and is helping me keep up with my team and get a better         understanding of the project as a whole. By time-boxing it to an hour         or two a day, I can ensure that I have time to fulfill my personal         responsibilities while still being accountable to the team. To         me, the biggest benefit of PR review besides QA and bug mitigation         is the sharing of knowledge.          <p>         A good PR should cleanly explain what the changes are, why they were         made, and what issues still exist in the affected code or linger         around the edges. This gives the reviewer a clear picture of the         motivation, allowing them to more easily see if the code completes         its objectives. The why gives insight into that developer's         perspective on the project as a whole, the issue in specific, and         their general problem solving approach. This can be incredibly         insightful, especially as a relatively new engineer, as it provides         a clear window into how my colleagues see things. When done well,         this can be a direct transfer of skills and knowledge that allows         the reviewer to become a better developer themselves.          <p>         Finishing with         the remaining issues and other concerns helps share that developer's         perspective on what work still has to be done. This spreads         project specific information which can help eliminate borders in         knowledge. It is never good to have a part of the code that         "only X understands, go ask them". While levels of expertise and         understanding vary, everyone on the team should have a minimally         workable understanding of each part of the codebase. This makes         the team more resilient to outside events while again         pushing each member's boundaries and ultimately making them better         at what they do.          <p>         If a team can consistently open concise, well explained PRs         that provide meaningful information and definitive improvements to         their project, both the final product and the engineers themselves will         improve. Do this for a period of time and a deeply valuable product         and team can be built. To be kitschy:         <blockquote>           software development is about developing software as much as           it is about developing the people who create it         </blockquote>  
        ]]></description>
      </item>
    

      <item>
        <title>4</title>
        <link>http://ephjos.io/daily/2021/10/10</link>
        <guid>http://ephjos.io/daily/2021/10/10</guid>
        <pubDate>Sun, 10 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <p>         I've hit that point in implementing a ray tracer where I need to         start implementing structs that have 2D arrays. This is needed         for the canvas' pixels and eventually in the matrix implementation.         This is straightforward enough in an imperative language, but has been         a sticking point in the past.          <p>         After some brief research, Racket's mutable vectors seem easy enough to         use, and are probably exactly what I need in this case. I want to         try to avoid building up thunks in these areas of the code as that         can lead to a massive space leak (as I've learned in the past).          <p>         If Racket's vectors are anything like those from Haskell, I'll         most likely wind up falling back to Python just to finish this project.          <p>         Wish me luck. 
        ]]></description>
      </item>
    

      <item>
        <title>3</title>
        <link>http://ephjos.io/daily/2021/10/09</link>
        <guid>http://ephjos.io/daily/2021/10/09</guid>
        <pubDate>Sat, 09 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <p>         I've always wanted to write a somewhat substantial program         using a Lisp. I was first introduced to the family of languages in         a programming languages course: good-old MIT Scheme. This was         such a foreign experience at the time both around tooling and the         language itself. This opened up a whole other world of programming         languages that led to me finding Haskell and Racket. However,         I've never written anything too complex with either (aside from the         <a href="https://mitpress.mit.edu/sites/default/files/sicp/full-text/sicp/book/node76.html">SICP metacircular evaluator</a>).          <p>         There has been an ongoing cycle of start-stop-delete with my attempts at         <a href="https://pragprog.com/titles/jbtracer/the-ray-tracer-challenge/">The Ray Tracer Challenge</a>,         which will warrant a more lengthy post. These days, I am working through         this book in Racket. Just in the first chapter I've learned a bit more         about the language and its tooling, and I look forward to the rest.          <p>         I am thinking about stopping and just crunching through the book in         Python to get myself all the way through it. Maybe a first pass with         relatively low friction will help me actually get through it using         the other languages I have in mind. So far focusing on reducing friction         and finsihing things has served me well, so maybe that's what it needed         here.          <p>         I also still need to bring over a couple of my old blog posts to this         version of the site. 
        ]]></description>
      </item>
    

      <item>
        <title>2</title>
        <link>http://ephjos.io/daily/2021/10/08</link>
        <guid>http://ephjos.io/daily/2021/10/08</guid>
        <pubDate>Fri, 08 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
                <p>         So about that whole "rss feed by hand" thing.          <p>         I spent some time this morning writing a couple bash scripts         that iterate over the files for both blogs and         generates each their own rss feed <i>and</i> index page. This greatly         reduces the amount of work necessary for each post, while also forcing         me to stay in this simple format.          <p>         Yes, I am looking at the inflexibility of a hacked together bash script         as a feature, not a bug in this case. I also committed the sin of         using regex to parse text out of HTML, <a href="https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454"         >but I think I'll be okay</a>.          <p>         All in all, I am pretty happy with how everything works right now. To         create a post I copy my template file to the new post, write it, and         run a bash script before pushing git and docker. As long as I follow         some simple formatting that my scripts expect, all should be well.          <p>         I also noticed some super strange caching behavior when testing the         site on my other devices yesterday, so I am pushing a change to stop         caching. These pages are small and lightweight enough that it shouldn't         matter, future me can worry about that. 
        ]]></description>
      </item>
    

      <item>
        <title>1</title>
        <link>http://ephjos.io/daily/2021/10/07</link>
        <guid>http://ephjos.io/daily/2021/10/07</guid>
        <pubDate>Thu, 07 Oct 2021 12:00:00 -0400</pubDate>
        <description><![CDATA[
              <p>       This is my first daily post. I am not really sure what this       will turn out to be, but I do want to see how far I can take it.       This will just be a place to jot down what's on my mind at       the time. Posts like projects or other more involved writing       will go in the main blog.        <p>       As of now, I am working on laying the website out again (for I       believe the 6th time). I am keeping the majority of the       UI/UX the same, but moving completely to a plain HTML/CSS/JS       stack.        <p>       I found out about SSI (Server Side Includes) the other day,       so I don't even need to use an external templating system.       Just set <code>ssi on</code> in nginx and get up and running.       This lets me share the head, navbar, and footer between pages       easily which was always my main deterrent from dropping all       the way down to bare HTML.        <p>       I've previously told myself that I don't like writing HTML and       that I <b>needed</b> a markdown setup in order to write, but       that certainly didn't lead to more writing.        <p>       So now, everything is dead simple. These posts don't       even really need markup, and in the cases that they do I'm       sure I'll get around to adding some useful snippets to my       vim config.        <p>       Creating the index pages and rss feed by hand is a bit strange,       but the whole theme of this effort is to <i>just do it</i>.        <p>       Here it goes! 
        ]]></description>
      </item>
    

</channel>
</rss>

